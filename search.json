[{"path":"https://mlverse.github.io/tft/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 tft authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"preparing-the-data","dir":"Articles","previous_headings":"","what":"Preparing the data","title":"Getting started","text":"first thing need make sure dataset doesn’t implicit missing observations. happens observations just present data instead explicitly marked NA. going use tsibble functionality add implicitly missing observations, use whatever tool prefer task.  also split full dataset 3 parts - training, validation testing. use last 24 weeks data validation/testing - using 16 validation 8 testing. Now data prepared create preprocessing pipeline using recipes package. recipe allow handling missing values normalization covariates - important neural network models. also adds covariates recommended paper authors like time_since_begining categoricals month week year.","code":"sales <- walmart_sales %>%     tsibble::tsibble(       key = c(Store, Dept),       index = Date     ) %>%     tsibble::group_by_key() %>%     tsibble::fill_gaps(       Weekly_Sales = 0,       IsHoliday = FALSE     ) %>%     tidyr::fill(Size, Temperature, Fuel_Price, CPI, Unemployment, .direction = \"down\") feasts::autoplot(sales, Weekly_Sales) #> `mutate_if()` ignored the following grouping variables: #> • Columns `Store`, `Dept` last_date <- max(sales$Date) sales_train <- sales %>% filter(Date <= (last_date - lubridate::weeks(24))) sales_valid <- sales %>% filter(Date > (last_date - lubridate::weeks(24)),                                 Date <= (last_date - lubridate::weeks(8))) sales_test <- sales %>% filter(Date > (last_date - lubridate::weeks(8))) rec <- recipe(Weekly_Sales ~ ., data = sales_train) %>%    step_mutate(     time_since_begining = as.numeric(difftime(       time1 = Date,        time2 = lubridate::ymd(min(sales$Date)),        units = \"weeks\"     )),     date_week = as.factor(lubridate::week(Date)),     date_month = as.factor(lubridate::month(Date)),     IsHoliday = as.factor(IsHoliday)   ) %>%    step_impute_median(starts_with(\"MarkDown\")) %>%    step_normalize(all_numeric_predictors())"},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"specifying-the-covariates","dir":"Articles","previous_headings":"","what":"Specifying the covariates","title":"Getting started","text":"Like said earlier, TFT allows encoding covariates differently architecture. 5 possible ways tft can treat columns dataset summarise : ‘index’: single date column specifies point time observation refers . directly used model , used internally create rolling windows order observations. ‘key’: groups columns identify single time series. Keys necessary creating predictions multiple time series single model. default, ‘keys’ also considered ‘static’ predictors model. ‘static’: predictors considered ‘static’ don’t vary time, information time-series, like region kind product. ‘unknown’ predictors vary time know values observed past observations. example, can use daily temperature predictor, know past observations. ‘known’ predictors vary time known even future observations. example, day week can used predictor daily time series, ’s known every time step, matter ’s past future. specify role covariate model use tft_dataset_spec() function. interface similar intent recipes (tidymodels), ie. allows reproduce preprocessing different dataset later - useful want create forecasts. Also part dataset specification history size model use make predictions size horizon (ie many time-steps ahead) want generate predictions. Consider following diagram represent time series Time series tft feeds data model slices fixed history size, call lookback fixed number timesteps ahead calling horizon. represented diagram : Slices Now lets create tft dataset specification. don’t need manually specfy unknown covariates , unmentioned variables automatically treated . print method spec shows useful information specification: see didn’t specify lookback horizon, let’s add spec. lookback usually works like hyperparameter general choose values 10 200 depending time series period. Horizon chosen statisfy business needs, ie. want predictions 4 weeks ahead, choose . now execute prep prepare spec: print method now shows name variables used model role. Also shows information number slices used.","code":"spec <- tft_dataset_spec(rec, sales_train) %>%    spec_covariate_index(Date) %>%    spec_covariate_keys(Store, Dept) %>%   spec_covariate_static(Type, Size) %>%    spec_covariate_known(starts_with(\"MarkDown\"), time_since_begining,                         starts_with(\"date_\"), IsHoliday) spec #> A <tft_dataset_spec> with: #>  #> ✖ `lookback` and `horizon` are not set. Use `spec_time_splits()`  #>  #> ── Covariates:  #> ✔ `index`: Date #> ✔ `keys`: <list: Store, Dept> #> ✔ `static`: <list: Type, Size> #> ✔ `known`: <list: starts_with(\"MarkDown\"), time_since_begining, starts_with(\"date_\"), and IsHoliday> #> ! `unknown` is not set. Covariates that are not listed as other types are considered `unknown`. #>  #> ℹ Call `prep()` to prepare the specification. spec <- spec %>%    spec_time_splits(lookback = 52, horizon = 4) spec <- prep(spec) spec #> A <prepared_tft_dataset_spec> with: #>  #> ✔ lookback = 52 and horizon = 4. #> ✔ The number of possible slices is 256 #>  #> ── Covariates:  #> ✔ `index`: Date #> ✔ `keys`: Store and Dept #> ✔ `static`: Type and Size #> ✔ `known`: MarkDown1, MarkDown2, MarkDown3, MarkDown4, MarkDown5, time_since_begining, date_week, date_month, and IsHoliday #> ✔ `unknown`: Temperature, Fuel_Price, CPI, and Unemployment #> ℹ Variables that are not specified in other types are considered `unknown`. #>  #> ℹ Call `transform()` to apply this spec to a different dataset."},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting the model","title":"Getting started","text":"now fit model. first initialize model : model luz module, thus can use luz workflows train model. example, can use lr_finder function find best learning rate model.  allows us choose learning rate. start 1e-3. Let’s redefine model now fixing learning rate: can fit model using fit. Since model luz module mainly calling ?fit.luz_module_generator , arguments apply.  happy results model can make predictions. model trained can make predictions 4 weeks ahead, test set 8 weeks ahead. order validate model, going create 2 test sets combine metrics. rolling_predict function , don’t need manually implement : return value rolling_predict tibble containing past_data, new_data .pred (predictions) slice made test data. can make plot predictions along historical data used creating predictions observed values.  create predictions future data, don’t yet target, can use predict. example: can show predictions plot:","code":"model <- temporal_fusion_transformer(spec, hidden_state_size = 128) model #> <luz_module_generator> result <- luz::lr_finder(   model,    transform(spec, sales_train),    end_lr = 1,   dataloader_options = list(     batch_size = 64   ),   verbose = FALSE ) plot(result) + ggplot2::coord_cartesian(ylim = c(0.15, 0.5)) model <- temporal_fusion_transformer(spec, hidden_state_size = 128,                                      learn_rate = 1e-3) fitted <- model %>%    fit(     transform(spec, sales_train),     valid_data = transform(spec, new_data = sales_valid),     epochs = 100,     callbacks = list(       luz::luz_callback_keep_best_model(monitor = \"valid_loss\"),       luz::luz_callback_early_stopping(         monitor = \"valid_loss\",          patience = 10,          min_delta = 0.001       )     ),     verbose = FALSE   ) plot(fitted) preds <- rolling_predict(   fitted,    past_data = dplyr::bind_rows(sales_train, sales_valid),   new_data = sales_test ) preds #> # A tibble: 2 × 3 #>   past_data           new_data           .pred             #>   <list>              <list>             <list>            #> 1 <tibble [208 × 16]> <tibble [16 × 16]> <tibble [16 × 3]> #> 2 <tibble [208 × 16]> <tibble [16 × 16]> <tibble [16 × 3]> preds %>%    rowwise() %>%    summarise(     past_data %>%        bind_rows(bind_cols(new_data, .pred)) %>%        mutate(.pred_at = max(past_data$Date))   ) %>%    ggplot(aes(x = Date)) +   geom_point(aes(y = Weekly_Sales)) +   geom_line(aes(y = Weekly_Sales)) +   geom_point(aes(y = .pred), color = \"red\") +   geom_line(aes(y = .pred), color = \"red\") +   facet_grid(Store + Dept ~ .pred_at, scales = \"free\") #> Warning: Removed 416 rows containing missing values (geom_point). #> Warning: Removed 52 row(s) containing missing values (geom_path). future_data <- walmartdata::walmart_sales_test %>%    filter(Store %in% c(1, 2), Dept %in% c(92, 95)) %>%    mutate(Store = as.factor(Store), Dept = as.factor(Dept)) %>%    filter(Date <= (max(sales$Date) + lubridate::weeks(4)))  pred <- predict(   fitted,   new_data = future_data,   past_data = sales ) sales %>%    filter(Date >= lubridate::ymd(\"2012-01-01\")) %>%    bind_rows(bind_cols(future_data, pred)) %>%    ggplot(aes(x = Date)) +   geom_point(aes(y = Weekly_Sales)) +   geom_line(aes(y = Weekly_Sales)) +   geom_point(aes(y = .pred), color = \"red\") +   geom_line(aes(y = .pred), color = \"red\") +   facet_grid(Store ~ Dept, scales = \"free\") #> Warning: Removed 16 rows containing missing values (geom_point). #> Warning: Removed 4 row(s) containing missing values (geom_path). #> Warning: Removed 172 rows containing missing values (geom_point). #> Warning: Removed 43 row(s) containing missing values (geom_path)."},{"path":"https://mlverse.github.io/tft/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Falbel. Author, maintainer. RStudio. Copyright holder. Christophe Regouby. Author.","code":""},{"path":"https://mlverse.github.io/tft/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Falbel D, Regouby C (2022). tft: Implementation Temporal Fusion Transformer. R package version 0.0.0.9000, https://mlverse.github.io/tft/.","code":"@Manual{,   title = {tft: Implementation of Temporal Fusion Transformer},   author = {Daniel Falbel and Christophe Regouby},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://mlverse.github.io/tft/}, }"},{"path":"https://mlverse.github.io/tft/index.html","id":"tft","dir":"","previous_headings":"","what":"Implementation of Temporal Fusion Transformer","title":"Implementation of Temporal Fusion Transformer","text":"R implementation : tft: Temporal Fusion Transformer. code repository R port akeskiner/Temporal_Fusion_Transform PyTorch’s implementation using torch package.","code":""},{"path":"https://mlverse.github.io/tft/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Implementation of Temporal Fusion Transformer","text":"can install development version {tft} GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"mlverse/tft\")"},{"path":"https://mlverse.github.io/tft/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Implementation of Temporal Fusion Transformer","text":"","code":"library(tft) library(rsample) suppressMessages(library(recipes)) suppressMessages(library(yardstick)) suppressMessages(library(tsibble)) set.seed(1)  data(\"vic_elec\", package = \"tsibbledata\") vic_elec <- vic_elec %>%    mutate(Location = as.factor(\"Victoria\"))  str(vic_elec) #> tbl_ts [52,608 × 6] (S3: tbl_ts/tbl_df/tbl/data.frame) #>  $ Time       : POSIXct[1:52608], format: \"2012-01-01 00:00:00\" \"2012-01-01 00:30:00\" ... #>  $ Demand     : num [1:52608] 4383 4263 4049 3878 4036 ... #>  $ Temperature: num [1:52608] 21.4 21.1 20.7 20.6 20.4 ... #>  $ Date       : Date[1:52608], format: \"2012-01-01\" \"2012-01-01\" ... #>  $ Holiday    : logi [1:52608] TRUE TRUE TRUE TRUE TRUE TRUE ... #>  $ Location   : Factor w/ 1 level \"Victoria\": 1 1 1 1 1 1 1 1 1 1 ... #>  - attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame) #>   ..$ .rows: list<int> [1:1]  #>   .. ..$ : int [1:52608] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..@ ptype: int(0)  #>  - attr(*, \"index\")= chr \"Time\" #>   ..- attr(*, \"ordered\")= logi TRUE #>  - attr(*, \"index2\")= chr \"Time\" #>  - attr(*, \"interval\")= interval [1:1] 30m #>   ..@ .regular: logi TRUE vic_elec_split <- initial_time_split(vic_elec, prop=3/4, lag=96)    vic_elec_train <- training(vic_elec_split) vic_elec_test <- testing(vic_elec_split)  rec <- recipe(Demand ~ ., data = vic_elec_train) %>%   update_role(Date, new_role=\"id\") %>%   update_role(Time, new_role=\"time\") %>%   update_role(Temperature, new_role=\"observed_input\") %>%   update_role(Holiday, new_role=\"known_input\") %>%   update_role(Location, new_role=\"static_input\") %>%   step_normalize(all_numeric(), -all_outcomes())   fit <- tft_fit(rec, vic_elec_train, epochs = 100, batch_size=100, total_time_steps=12, num_encoder_steps=10, verbose=TRUE)  yhat <- predict(fit, rec, vic_elec_test)"},{"path":"https://mlverse.github.io/tft/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a model\nSee generics::fit() for more information. — fit","title":"Fit a model\nSee generics::fit() for more information. — fit","text":"Fit model See generics::fit() information.","code":""},{"path":"https://mlverse.github.io/tft/reference/fit.tft_module.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit the Temporal Fusion Transformer module — fit.tft_module","title":"Fit the Temporal Fusion Transformer module — fit.tft_module","text":"Fit Temporal Fusion Transformer module","code":""},{"path":"https://mlverse.github.io/tft/reference/fit.tft_module.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit the Temporal Fusion Transformer module — fit.tft_module","text":"","code":"# S3 method for tft_module fit(object, ...)"},{"path":"https://mlverse.github.io/tft/reference/fit.tft_module.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit the Temporal Fusion Transformer module — fit.tft_module","text":"object TFT module created temporal_fusion_transformer(). ... Arguments passed luz::fit.luz_module_generator().","code":""},{"path":"https://mlverse.github.io/tft/reference/forecast.tft_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate forecasts for TFT models — forecast.tft_result","title":"Generate forecasts for TFT models — forecast.tft_result","text":"forecast can used model object include known predictors must exist data. fine recipe passed tft_dataset_spec() computes known predictors though.","code":""},{"path":"https://mlverse.github.io/tft/reference/forecast.tft_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate forecasts for TFT models — forecast.tft_result","text":"","code":"# S3 method for tft_result forecast(object, horizon = NULL)"},{"path":"https://mlverse.github.io/tft/reference/forecast.tft_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate forecasts for TFT models — forecast.tft_result","text":"object tft_result object used create predictions. horizon Number time steps ahead generate predictions.","code":""},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mlverse.github.io/tft/reference/predict.tft_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict for TFT — predict.tft_result","title":"Predict for TFT — predict.tft_result","text":"Predict TFT","code":""},{"path":"https://mlverse.github.io/tft/reference/predict.tft_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict for TFT — predict.tft_result","text":"","code":"# S3 method for tft_result predict(object, new_data = NULL, ..., past_data = NULL)"},{"path":"https://mlverse.github.io/tft/reference/predict.tft_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict for TFT — predict.tft_result","text":"object model object prediction desired. new_data data.frame() containing dataset generate predictions . general used pass static known information generate forecasts. ... arguments passed predict.luz_module_fitted(). past_data data.frame() past information creating predictions. include least lookback values - can . concatenated new_data passing forward. NULL, data used train model used.","code":""},{"path":"https://mlverse.github.io/tft/reference/prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a specification\nSee recipes::prep() for more information. — prep","title":"Prepare a specification\nSee recipes::prep() for more information. — prep","text":"Prepare specification See recipes::prep() information.","code":""},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Defines rolling slices — rolling_predict","title":"Defines rolling slices — rolling_predict","text":"Sometimes validation testing data values horizon model still want create predictions time step .","code":""},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Defines rolling slices — rolling_predict","text":"","code":"rolling_predict(object, past_data, new_data, step = NULL)"},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Defines rolling slices — rolling_predict","text":"object model object prediction desired. past_data data.frame() past information creating predictions. include least lookback values - can . concatenated new_data passing forward. NULL, data used train model used. new_data data.frame() containing dataset generate predictions . general used pass static known information generate forecasts. step Default step horizon o model, way one prediction per slice.","code":""},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Defines rolling slices — rolling_predict","text":"function combine past_data (can also include training data) create slices create predictions value new_data.","code":""},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Group normalization — step_group_normalize","title":"Group normalization — step_group_normalize","text":"recipes::recipe() step normalizing data per group. times want normalize time series independently might different scales.","code":""},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group normalization — step_group_normalize","text":"","code":"step_group_normalize(   recipe,   ...,   groups,   stats = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"group_normalize\") )"},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group normalization — step_group_normalize","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See selections() details. groups <tidy-select> Columns group computing normalization statistics. stats modified prep. data frame containing one row per distinct group, containing normalization statistics. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion transformer — temporal_fusion_transformer","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"Temporal Fusion transformer Configuration tft model","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"","code":"temporal_fusion_transformer(spec, ...)  tft_config(   hidden_state_size = 16,   num_attention_heads = 4,   num_lstm_layers = 2,   dropout = 0.1,   optimizer = \"adam\",   learn_rate = 0.01,   quantiles = c(0.1, 0.5, 0.9) )"},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"spec spec created tft_dataset_spec(). required model depends information created/defined dataset. ... Additional parameters passed tft_config(). hidden_state_size Hidden size network main hyperparameter can range 8 512. also known d_model across paper. num_attention_heads Number attention heads Multi-head attention layer. paper refer m_H. 4 good default. num_lstm_layers Number LSTM layers used Locality Enhancement Layer. Usually 2 good enough. dropout Dropout rate used many places architecture. optimizer Optimizer used training. Can string 'adam', 'sgd', 'adagrad'. Can also torch::optimizer(). learn_rate Leaning rate used optimizer. quantiles numeric vector 3 quantiles quantile loss. first treated lower bound interval, second point prediction thir upper bound.","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"luz_module setup ready fitted.","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"temporal_fusion_transformer: Create tft module tft_config: Configuration Temporal Fusion Transformer","code":""},{"path":[]},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"Temporal Fusion Transformer Module","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"","code":"temporal_fusion_transformer_model(   num_features,   feature_sizes,   hidden_state_size = 100,   dropout = 0.1,   num_heads = 4,   num_lstm_layers = 2,   num_quantiles = 3 )"},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"num_features list containing shapes necessary information define size layers, including: - $encoder$past$(num|cat): shape past features - $encoder$static$(num|cat): shape static features - $decoder$target: shape target variable exclude batch dimension. feature_sizes number unique elements categorical variable dataset. hidden_state_size size model shared accross multiple parts architecture. dropout Dropout rate used many different places network num_heads Number heads attention layer. num_lstm_layers Number LSTM layers used Locality Enhancement Layer. Usually 2 good enough. num_quantiles number quantiles predicting .","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a TFT data specification — tft_dataset_spec","title":"Creates a TFT data specification — tft_dataset_spec","text":"used create torch::dataset()s training model, take care target normalization allow initializing temporal_fusion_transformer() model, requires specification passed first argument.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a TFT data specification — tft_dataset_spec","text":"","code":"tft_dataset_spec(x, ...)  spec_time_splits(spec, lookback, horizon)  spec_covariate_index(spec, index)  spec_covariate_keys(spec, ...)  spec_covariate_known(spec, ...)  spec_covariate_unknown(spec, ...)  spec_covariate_static(spec, ...)"},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a TFT data specification — tft_dataset_spec","text":"x recipe data.frame used obtain statiscs preparing recipe preparing dataset. ... Column names, selected using tidyselect. See <tidy-select> information. spec spec created tft_dataset_spec(). lookback Number timesteps used historic data prediction. horizon Number timesteps ahead predicted model. index column name indexes data. Usually date column.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a TFT data specification — tft_dataset_spec","text":"tft_dataset_spec can add spec_ functions using |> (pipe) prep() done transform() obtain torch::dataset()s.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Creates a TFT data specification — tft_dataset_spec","text":"spec_time_splits: Sets lookback horizon parameters. spec_covariate_index: Sets index column. spec_covariate_keys: Sets keys - variables define time series spec_covariate_known: Sets known time varying covariates. spec_covariate_unknown: Sets unknown time varying covariates. spec_covariate_static: Sets static covariates.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a TFT data specification — tft_dataset_spec","text":"","code":"if (torch::torch_is_installed()) { sales <- walmartdata::walmart_sales %>%   dplyr::filter(Store == 1, Dept %in% c(1,2))  rec <- recipes::recipe(Weekly_Sales ~ ., sales)  spec <- tft_dataset_spec(rec, sales) %>%   spec_time_splits(lookback = 52, horizon = 4) %>%   spec_covariate_index(Date) %>%   spec_covariate_keys(Store, Dept) %>%   spec_covariate_static(Type, Size) %>%   spec_covariate_known(starts_with(\"MarkDown\"))  print(spec)  spec <- prep(spec) dataset <- transform(spec) # this is a torch dataset. str(dataset[1]) } #> A <tft_dataset_spec> with: #>  #> ✔ lookback = 52 and horizon = 4. #>  #> ── Covariates:  #> ✔ `index`: Date #> ✔ `keys`: <list: Store, Dept> #> ✔ `static`: <list: Type, Size> #> ✔ `known`: <list: starts_with(\"MarkDown\")> #> ! `unknown` is not set. Covariates that are not listed as other types are considered `unknown`. #>  #> ℹ Call `prep()` to prepare the specification. #> List of 2 #>  $ :List of 2 #>   ..$ encoder:List of 2 #>   .. ..$ past  :List of 2 #>   .. .. ..$ num:Float [1:52, 1:11] #>   .. .. ..$ cat:Float [1:0, 1:0] #>   .. ..$ static:List of 2 #>   .. .. ..$ num:Float [1:3] #>   .. .. ..$ cat:Long [1:1] #>   ..$ decoder:List of 2 #>   .. ..$ known :List of 2 #>   .. .. ..$ num:Float [1:4, 1:5] #>   .. .. ..$ cat:Float [1:0, 1:0] #>   .. ..$ target:List of 2 #>   .. .. ..$ num:Float [1:4, 1:1] #>   .. .. ..$ cat:Float [1:0, 1:0] #>  $ :Float [1:4, 1:1]"},{"path":"https://mlverse.github.io/tft/news/index.html","id":"tft-0009000","dir":"Changelog","previous_headings":"","what":"tft 0.0.0.9000","title":"tft 0.0.0.9000","text":"remove constraint development versions torch:: recipe:: Added NEWS.md file track changes package.","code":""}]
