[{"path":"https://mlverse.github.io/tft/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 tft authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"preparing-the-data","dir":"Articles","previous_headings":"","what":"Preparing the data","title":"Getting started","text":"first thing need make sure dataset doesn’t implicit missing observations. happens observations just present data instead explicitly marked NA. going use tsibble functionality add implicitly missing observations, use whatever tool prefer task. tft can treat columns dataset differently depending types. mainly 5 types columns: ‘index’: single date column specifies point time observation refers . directly used model , used internally create rolling windows order observations. ‘key’: groups columns identify single time series. Keys necessary creating predictions multiple time series single model. default, ‘keys’ considered ‘static’ predictors model. ‘static’: predictors considered ‘static’ don’t vary time, information time-series, like region kind product. ‘unknown’ predictors vary time know values observed past observations. example, can use daily temperature predictor, know past observations. ‘known’ predictors vary time known even future observations. example, day week can used predictor daily time series, ’s known every time step, matter ’s past future. recipes package used specify model treat column dataset. ’s recommended include features represent seasonality known predictors TFT model, like mon, day week etc. ’s also recommended normalize predictors treat missing values model don’t treat implicitly. can bake prep juice recipe see transformations working:","code":"sales <- walmart_sales %>%     tsibble::tsibble(       key = c(Store, Dept, Type, Size),       index = Date     ) %>%     tsibble::group_by_key() %>%     tsibble::fill_gaps(       Weekly_Sales = 0,       IsHoliday = FALSE     ) %>%     tidyr::fill(Size, Temperature, Fuel_Price, CPI, Unemployment, .direction = \"down\") rec <- recipe(Weekly_Sales ~ ., data = sales) %>%    update_role(Date, new_role = \"index\") %>%    update_role(Store, Dept, Type, Size, new_role = \"key\") %>%    update_role(IsHoliday, new_role = \"known\") %>%    step_date(Date, role = \"known\", features = c(\"year\", \"month\", \"doy\")) %>%    step_normalize(all_numeric_predictors()) %>%    step_indicate_na(starts_with(\"MarkDown\")) %>%    step_impute_mean(starts_with(\"Markdown\")) %>%    step_include_roles() rec %>% prep() %>% juice() %>% glimpse() #> Rows: 572 #> Columns: 24 #> $ Store            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ Dept             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ Date             <date> 2010-02-05, 2010-02-12, 2010-02-19, 2010-02-26, 2010… #> $ Type             <fct> A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A,… #> $ Size             <dbl> 151315, 151315, 151315, 151315, 151315, 151315, 15131… #> $ Temperature      <dbl> -1.74810944, -2.00407912, -1.90842730, -1.45711234, -… #> $ Fuel_Price       <dbl> -1.5197484, -1.5760615, -1.6558384, -1.5455586, -1.39… #> $ MarkDown1        <dbl> 2.135878e-17, 2.135878e-17, 2.135878e-17, 2.135878e-1… #> $ MarkDown2        <dbl> 7.530688e-18, 7.530688e-18, 7.530688e-18, 7.530688e-1… #> $ MarkDown3        <dbl> -2.445418e-17, -2.445418e-17, -2.445418e-17, -2.44541… #> $ MarkDown4        <dbl> 8.185461e-18, 8.185461e-18, 8.185461e-18, 8.185461e-1… #> $ MarkDown5        <dbl> 5.606176e-17, 5.606176e-17, 5.606176e-17, 5.606176e-1… #> $ CPI              <dbl> -1.089091, -1.055483, -1.044657, -1.037627, -1.030597… #> $ Unemployment     <dbl> 0.9556973, 0.9556973, 0.9556973, 0.9556973, 0.9556973… #> $ IsHoliday        <lgl> FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE… #> $ Weekly_Sales     <dbl> 24924.50, 46039.49, 41595.55, 19403.54, 21827.90, 210… #> $ Date_year        <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010,… #> $ Date_month       <fct> Feb, Feb, Feb, Feb, Mar, Mar, Mar, Mar, Apr, Apr, Apr… #> $ Date_doy         <dbl> 36, 43, 50, 57, 64, 71, 78, 85, 92, 99, 106, 113, 120… #> $ na_ind_MarkDown1 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown2 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown3 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown4 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown5 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…"},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"metrics-and-validation","dir":"Articles","previous_headings":"","what":"Metrics and validation","title":"Getting started","text":"Now think size horizon want create forecasts . single week ahead ten, influence split data training, validation testing. really data analysis decision business decision, ie: many weeks ahead want know can plan demand etc. Let’s say want 4 weeks ahead, ie ~1 month. rsample package provides sliding_* functions useful task creating time splits. Now can separate splits , training testing, ie: used cross-validation choosing hyperparamerters, others used testing model. going use last 4 splits testing first 5 cross validate. Note: selected 4 weeks horizon predictions. need use value specifying horizon tft model.","code":"resamples <- sliding_period(   arrange(sales, Date),   index = Date,   period = \"week\",   lookback = Inf,   assess_stop = 4,   step = 4,   skip = 104 ) train_splits <- resamples %>%    slice(1:5) %>%    structure(class = \"rset\") test_splits <- resamples %>%    slice(-c(1:5)) %>%    structure(class = \"rset\")"},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting the model","title":"Getting started","text":"can now tune tft model compute metrics using:  happy tuning can finalize workflow obtain metrics test splits. obtain predictions future observations, first need load data.frame includes known predictors like IsHoliday variable time steps future data frame. can call forecast predict obtain predictions future data. Note forecast predict currently can predict horizon time steps ahead. don’t provide away rolling forecasts.","code":"tft_model <- temporal_fusion_transformer(   horizon = 4,    lookback = 100,    hidden_state_size = tune() ) %>%    set_engine(\"torch\", verbose = FALSE) %>%    set_mode(\"regression\")   model <- workflow() %>%    add_recipe(rec) %>%    add_model(tft_model)  grid <- tibble::tibble(   hidden_state_size = c(4, 16, 32) )  results <- tune_grid(   model,   resamples = train_splits,   grid = grid,   control = control_grid(verbose = TRUE) ) #> i Slice1: preprocessor 1/1 #> ✓ Slice1: preprocessor 1/1 #> i Slice1: preprocessor 1/1, model 1/3 #> ✓ Slice1: preprocessor 1/1, model 1/3 #> i Slice1: preprocessor 1/1, model 1/3 (predictions) #> i Slice1: preprocessor 1/1, model 2/3 #> ✓ Slice1: preprocessor 1/1, model 2/3 #> i Slice1: preprocessor 1/1, model 2/3 (predictions) #> i Slice1: preprocessor 1/1, model 3/3 #> ✓ Slice1: preprocessor 1/1, model 3/3 #> i Slice1: preprocessor 1/1, model 3/3 (predictions) #> i Slice2: preprocessor 1/1 #> ✓ Slice2: preprocessor 1/1 #> i Slice2: preprocessor 1/1, model 1/3 #> ✓ Slice2: preprocessor 1/1, model 1/3 #> i Slice2: preprocessor 1/1, model 1/3 (predictions) #> i Slice2: preprocessor 1/1, model 2/3 #> ✓ Slice2: preprocessor 1/1, model 2/3 #> i Slice2: preprocessor 1/1, model 2/3 (predictions) #> i Slice2: preprocessor 1/1, model 3/3 #> ✓ Slice2: preprocessor 1/1, model 3/3 #> i Slice2: preprocessor 1/1, model 3/3 (predictions) #> i Slice3: preprocessor 1/1 #> ✓ Slice3: preprocessor 1/1 #> i Slice3: preprocessor 1/1, model 1/3 #> ✓ Slice3: preprocessor 1/1, model 1/3 #> i Slice3: preprocessor 1/1, model 1/3 (predictions) #> i Slice3: preprocessor 1/1, model 2/3 #> ✓ Slice3: preprocessor 1/1, model 2/3 #> i Slice3: preprocessor 1/1, model 2/3 (predictions) #> i Slice3: preprocessor 1/1, model 3/3 #> ✓ Slice3: preprocessor 1/1, model 3/3 #> i Slice3: preprocessor 1/1, model 3/3 (predictions) #> i Slice4: preprocessor 1/1 #> ✓ Slice4: preprocessor 1/1 #> i Slice4: preprocessor 1/1, model 1/3 #> ✓ Slice4: preprocessor 1/1, model 1/3 #> i Slice4: preprocessor 1/1, model 1/3 (predictions) #> i Slice4: preprocessor 1/1, model 2/3 #> ✓ Slice4: preprocessor 1/1, model 2/3 #> i Slice4: preprocessor 1/1, model 2/3 (predictions) #> i Slice4: preprocessor 1/1, model 3/3 #> ✓ Slice4: preprocessor 1/1, model 3/3 #> i Slice4: preprocessor 1/1, model 3/3 (predictions) #> i Slice5: preprocessor 1/1 #> ✓ Slice5: preprocessor 1/1 #> i Slice5: preprocessor 1/1, model 1/3 #> ✓ Slice5: preprocessor 1/1, model 1/3 #> i Slice5: preprocessor 1/1, model 1/3 (predictions) #> i Slice5: preprocessor 1/1, model 2/3 #> ✓ Slice5: preprocessor 1/1, model 2/3 #> i Slice5: preprocessor 1/1, model 2/3 (predictions) #> i Slice5: preprocessor 1/1, model 3/3 #> ✓ Slice5: preprocessor 1/1, model 3/3 #> i Slice5: preprocessor 1/1, model 3/3 (predictions)  autoplot(results) final_params <- select_best(results, metric = \"rmse\") model <- finalize_workflow(model, final_params) results <- fit_resamples(model, test_splits) collect_metrics(results) #> # A tibble: 2 × 6 #>   .metric .estimator     mean     n   std_err .config              #>   <chr>   <chr>         <dbl> <int>     <dbl> <chr>                #> 1 rmse    standard   5628.        4 1726.     Preprocessor1_Model1 #> 2 rsq     standard      0.962     4    0.0144 Preprocessor1_Model1 new_data <- walmartdata::walmart_sales_test %>%    filter(Store %in% c(1, 2), Dept %in% c(1,2)) %>%    filter(Date <= lubridate::ymd(\"2012-11-23\"))  final_model <- fit(model, sales) final_predictions <- predict(final_model, new_data = new_data) final_predictions #> # A tibble: 16 × 4 #>    .pred_lower  .pred .pred_upper .pred_at   #>          <dbl>  <dbl>       <dbl> <date>     #>  1      15550. 21479.      36981. 2012-10-26 #>  2      15531. 21458.      36960. 2012-10-26 #>  3      15517. 21451.      36957. 2012-10-26 #>  4      15507. 21448.      36962. 2012-10-26 #>  5      43671. 45741.      51153. 2012-10-26 #>  6      43664. 45734.      51146. 2012-10-26 #>  7      43659. 45731.      51145. 2012-10-26 #>  8      43656. 45730.      51147. 2012-10-26 #>  9      20656. 29270.      51799. 2012-10-26 #> 10      20629. 29241.      51769. 2012-10-26 #> 11      20607. 29230.      51766. 2012-10-26 #> 12      20593. 29227.      51773. 2012-10-26 #> 13      62476. 65401.      73050. 2012-10-26 #> 14      62467. 65391.      73039. 2012-10-26 #> 15      62460. 65387.      73039. 2012-10-26 #> 16      62455. 65386.      73041. 2012-10-26"},{"path":"https://mlverse.github.io/tft/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Falbel. Author, maintainer. RStudio. Copyright holder. Christophe Regouby. Author.","code":""},{"path":"https://mlverse.github.io/tft/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Falbel D, Regouby C (2022). tft: Implementation Temporal Fusion Transformer. R package version 0.0.0.9000, https://mlverse.github.io/tft/.","code":"@Manual{,   title = {tft: Implementation of Temporal Fusion Transformer},   author = {Daniel Falbel and Christophe Regouby},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://mlverse.github.io/tft/}, }"},{"path":"https://mlverse.github.io/tft/index.html","id":"tft","dir":"","previous_headings":"","what":"Implementation of Temporal Fusion Transformer","title":"Implementation of Temporal Fusion Transformer","text":"R implementation : tft: Temporal Fusion Transformer. code repository R port akeskiner/Temporal_Fusion_Transform PyTorch’s implementation using torch package.","code":""},{"path":"https://mlverse.github.io/tft/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Implementation of Temporal Fusion Transformer","text":"can install development version {tft} GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"mlverse/tft\")"},{"path":"https://mlverse.github.io/tft/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Implementation of Temporal Fusion Transformer","text":"","code":"library(tft) library(rsample) suppressMessages(library(recipes)) suppressMessages(library(yardstick)) suppressMessages(library(tsibble)) set.seed(1)  data(\"vic_elec\", package = \"tsibbledata\") vic_elec <- vic_elec %>%    mutate(Location = as.factor(\"Victoria\"))  str(vic_elec) #> tbl_ts [52,608 × 6] (S3: tbl_ts/tbl_df/tbl/data.frame) #>  $ Time       : POSIXct[1:52608], format: \"2012-01-01 00:00:00\" \"2012-01-01 00:30:00\" ... #>  $ Demand     : num [1:52608] 4383 4263 4049 3878 4036 ... #>  $ Temperature: num [1:52608] 21.4 21.1 20.7 20.6 20.4 ... #>  $ Date       : Date[1:52608], format: \"2012-01-01\" \"2012-01-01\" ... #>  $ Holiday    : logi [1:52608] TRUE TRUE TRUE TRUE TRUE TRUE ... #>  $ Location   : Factor w/ 1 level \"Victoria\": 1 1 1 1 1 1 1 1 1 1 ... #>  - attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame) #>   ..$ .rows: list<int> [1:1]  #>   .. ..$ : int [1:52608] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..@ ptype: int(0)  #>  - attr(*, \"index\")= chr \"Time\" #>   ..- attr(*, \"ordered\")= logi TRUE #>  - attr(*, \"index2\")= chr \"Time\" #>  - attr(*, \"interval\")= interval [1:1] 30m #>   ..@ .regular: logi TRUE vic_elec_split <- initial_time_split(vic_elec, prop=3/4, lag=96)    vic_elec_train <- training(vic_elec_split) vic_elec_test <- testing(vic_elec_split)  rec <- recipe(Demand ~ ., data = vic_elec_train) %>%   update_role(Date, new_role=\"id\") %>%   update_role(Time, new_role=\"time\") %>%   update_role(Temperature, new_role=\"observed_input\") %>%   update_role(Holiday, new_role=\"known_input\") %>%   update_role(Location, new_role=\"static_input\") %>%   step_normalize(all_numeric(), -all_outcomes())   fit <- tft_fit(rec, vic_elec_train, epochs = 100, batch_size=100, total_time_steps=12, num_encoder_steps=10, verbose=TRUE)  yhat <- predict(fit, rec, vic_elec_test)"},{"path":"https://mlverse.github.io/tft/reference/dataprep_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters related to data preparation in TFT — dataprep_parameters","title":"Parameters related to data preparation in TFT — dataprep_parameters","text":"Parameters related data preparation TFT","code":""},{"path":"https://mlverse.github.io/tft/reference/dataprep_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters related to data preparation in TFT — dataprep_parameters","text":"","code":"lookback(range = c(3L, 365L), trans = NULL)  horizon(range = c(1L, 365L), trans = NULL)  hidden_state_size(range = c(2L, 128L), trans = NULL)"},{"path":"https://mlverse.github.io/tft/reference/dataprep_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters related to data preparation in TFT — dataprep_parameters","text":"range two-element vector holding defaults smallest largest possible values, respectively. trans trans object scales package, scales::log10_trans() scales::reciprocal_trans(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"https://mlverse.github.io/tft/reference/dataprep_parameters.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Parameters related to data preparation in TFT — dataprep_parameters","text":"lookback: lookback Lookback history horizon: horizon Number steps multi-horizon forecast hidden_state_size: hidden_state_size Size network.","code":""},{"path":"https://mlverse.github.io/tft/reference/dataprep_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters related to data preparation in TFT — dataprep_parameters","text":"","code":"lookback() #> Lookback (quantitative) #> Range: [3, 365]"},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mlverse.github.io/tft/reference/predict.tft.html","id":null,"dir":"Reference","previous_headings":"","what":"Create predictions for TFT models — predict.tft","title":"Create predictions for TFT models — predict.tft","text":"Create predictions TFT models","code":""},{"path":"https://mlverse.github.io/tft/reference/predict.tft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create predictions for TFT models — predict.tft","text":"","code":"# S3 method for tft predict(object, new_data, type = \"numeric\", mode = \"horizon\", step = NULL, ...)"},{"path":"https://mlverse.github.io/tft/reference/predict.tft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create predictions for TFT models — predict.tft","text":"object model object prediction desired. new_data data.frame() containing dataset generate predictions . general used pass static known information generate forecasts. type Currently 'numeric' accepted might change future end supporting classification. mode Prediction mode. 'horizon' predict generate single multi-horizon prediction. mostly sueful creating forecasts time frame right model trained. 'full' predictions created every possible time step (possible step) argument. mode='horizon' (default) prediction columns returned. mode='full' columns new_data returned result might lines new_data potentially possible generate different predictions time-step. step Step predictions using mode='full'. ... additional arguments affecting predictions produced.","code":""},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Group normalization — step_group_normalize","title":"Group normalization — step_group_normalize","text":"recipes::recipe() step normalizing data per group. times want normalize time series independently might different scales.","code":""},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group normalization — step_group_normalize","text":"","code":"step_group_normalize(   recipe,   ...,   groups,   stats = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"group_normalize\") )"},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group normalization — step_group_normalize","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See selections() details. groups <tidy-select> Columns group computing normalization statistics. stats modified prep. data frame containing one row per distinct group, containing normalization statistics. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://mlverse.github.io/tft/reference/step_include_roles.html","id":null,"dir":"Reference","previous_headings":"","what":"Include roles — step_include_roles","title":"Include roles — step_include_roles","text":"recipes::recipe() step adds role information recipe attribute baked juiced output.","code":""},{"path":"https://mlverse.github.io/tft/reference/step_include_roles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Include roles — step_include_roles","text":"","code":"step_include_roles(   recipe,   roles = NULL,   trained = FALSE,   skip = FALSE,   role = NA,   id = recipes::rand_id(\"include_roles\") )"},{"path":"https://mlverse.github.io/tft/reference/step_include_roles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Include roles — step_include_roles","text":"recipe recipe object. step added sequence operations recipe. roles data.frame role information term created recipe. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. role used step since new variables created. id character string unique step identify .","code":""},{"path":"https://mlverse.github.io/tft/reference/step_include_roles.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Include roles — step_include_roles","text":"step must used last step recipe.","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"Temporal Fusion Transformer Module","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"","code":"temporal_fusion_transformer_model(   num_features,   feature_sizes,   hidden_state_size = 100,   dropout = 0.1,   num_heads = 4,   num_lstm_layers = 2,   num_quantiles = 3 )"},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"num_features list containing shapes necessary information define size layers, including: - $encoder$past$(num|cat): shape past features - $encoder$static$(num|cat): shape static features - $decoder$target: shape target variable exclude batch dimension. feature_sizes number unique elements categorical variable dataset. hidden_state_size size model shared accross multiple parts architecture. dropout Dropout rate used many different places network num_heads Number heads attention layer. num_lstm_layers Number LSTM layers used Locality Enhancement Layer. Usually 2 good enough. num_quantiles number quantiles predicting .","code":""},{"path":"https://mlverse.github.io/tft/reference/tft.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion Transformer — tft","title":"Temporal Fusion Transformer — tft","text":"Temporal Fusion Transformer Configuration Temporal Fusion Transformer network","code":""},{"path":"https://mlverse.github.io/tft/reference/tft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion Transformer — tft","text":"","code":"tft(x, ...)  tft_config(   lookback,   horizon,   subsample = 1,   hidden_state_size = 16,   num_attention_heads = 4,   num_lstm_layers = 2,   dropout = 0.1,   batch_size = 256,   epochs = 5,   optimizer = \"adam\",   learn_rate = 0.01,   learn_rate_decay = c(0.1, 5),   gradient_clip_norm = 0.1,   quantiles = c(0.1, 0.5, 0.9),   num_workers = 0,   verbose = FALSE )  temporal_fusion_transformer(   mode = \"regression\",   lookback = NULL,   horizon = NULL,   hidden_state_size = NULL,   dropout = NULL,   learn_rate = NULL,   batch_size = NULL,   epochs = NULL )"},{"path":"https://mlverse.github.io/tft/reference/tft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion Transformer — tft","text":"x recipe containing step_include_roles() last step. Can also data.frame, expect recipe attribute attribute containing recipe generated via recipes::bake() recipes::juice(). ... Additional arguments passed tft_config(). lookback Number timesteps used historic data prediction. horizon Number timesteps ahead predicted model. subsample Subsample possible slices. integer number samples proportion. hidden_state_size Hidden size network main hyperparameter can range 8 512. also known d_model across paper. num_attention_heads Number attention heads Multi-head attention layer. paper refer m_H. 4 good default. num_lstm_layers Number LSTM layers used Locality Enhancement Layer. Usually 2 good enough. dropout Dropout rate used many places architecture. batch_size many samples per batch load. epochs Maximum number epochs training model. optimizer Optimizer used training. Can string 'adam', 'sgd', 'adagrad'. Can also torch::optimizer(). learn_rate Leaning rate used optimizer. learn_rate_decay Decrease learning rate factor epoch. Can also vector 2 elements. case decrease learning x[1] every x[2] epochs - (x learn_rate_decay vector.) Use FALSE negative number disable. gradient_clip_norm Maximum norm gradients. Passed luz::luz_callback_gradient_clip(). <= 0 FALSE gradient clipping performed. quantiles numeric vector 3 quantiles quantile loss. first treated lower bound interval, second point prediction thir upper bound. num_workers Number parallel workers preprocessing data. verbose Logical value stating model produce status outputs, like progress bar, training. mode single character string type model. possible value model \"regression\".","code":""},{"path":"https://mlverse.github.io/tft/reference/tft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal Fusion Transformer — tft","text":"list configuration parameters.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Temporal Fusion Transformer — tft","text":"tft_config: Configuration configuration options tft. temporal_fusion_transformer: Parsnip wrappers TFT.","code":""},{"path":[]},{"path":"https://mlverse.github.io/tft/news/index.html","id":"tft-0009000","dir":"Changelog","previous_headings":"","what":"tft 0.0.0.9000","title":"tft 0.0.0.9000","text":"remove constraint development versions torch:: recipe:: Added NEWS.md file track changes package.","code":""}]
