[{"path":"https://mlverse.github.io/tft/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 tft authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"preparing-the-data","dir":"Articles","previous_headings":"","what":"Preparing the data","title":"Getting started","text":"first display data 7 reservoirs:  reduce computation time make model useful, going aggregate data weekly intervals. leave us much smaller dataset, make model much faster train. also allows us choose larger horizon. used mean o aggregate variables even though volume_variation now much harder interpret. new dataset looks like:  level can go 0%, means water called ‘technical water reserve’, ie water level usual water pipes used. happened severe drought hit region 2014 2017. goal predict reservoir level 3 months (12 weeks precise). split dataset 3 parts. last 3 months testing, previous 3 validation rest training model. Now data prepared create preprocessing pipeline using recipes package. recipe allow handling normalization covariates - important neural network models. also adds covariates recommended paper authors like time_since_beginingand categoricals month week year.","code":"reservoirs %>%    ggplot(aes(x = date, y = volume_percentage, color = system)) +   geom_line() reservoirs <- reservoirs %>%    mutate(date = lubridate::floor_date(date, unit = \"week\")) %>%    group_by(date, system) %>%    summarise(across(everything(), .fns = ~mean(.x, na.rm = TRUE)), .groups = \"drop\") reservoirs %>%    ggplot(aes(x = date, y = volume_percentage, color = system)) +   geom_line() last_date <- max(reservoirs$date) train <- reservoirs %>% filter(date <= (last_date - lubridate::weeks(48))) valid <- reservoirs %>% filter(date > (last_date - lubridate::weeks(48)),                                 date <= (last_date - lubridate::weeks(12))) test <- reservoirs %>% filter(date > (last_date - lubridate::weeks(12))) rec <- recipe(volume_percentage ~ ., data = train) %>%    step_mutate(     time_since_begining = as.numeric(difftime(       time1 = date,        time2 = lubridate::ymd(min(reservoirs$date)),        units = \"weeks\"     )),     date_week = as.factor(lubridate::week(date)),     date_month = as.factor(lubridate::month(date)),     date_wday = as.factor(lubridate::wday(date))   ) %>%    step_impute_mean(pluviometric_hist) %>%    step_normalize(all_numeric_predictors())"},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"specifying-the-covariates","dir":"Articles","previous_headings":"","what":"Specifying the covariates","title":"Getting started","text":"Like said earlier, TFT allows encoding covariates differently architecture. 5 possible ways tft can treat columns dataset summarise : ‘index’: single date column specifies point time observation refers . directly used model , used internally create rolling windows order observations. ‘key’: groups columns identify single time series. Keys necessary creating predictions multiple time series single model. default, ‘keys’ also considered ‘static’ predictors model. ‘static’: predictors considered ‘static’ don’t vary time, information time-series, like region kind product. ‘unknown’ predictors vary time know values observed past observations. example, can use daily temperature predictor, know past observations. ‘known’ predictors vary time known even future observations. example, day week can used predictor daily time series, ’s known every time step, matter ’s past future. specify role covariate model use tft_dataset_spec() function. interface similar intent recipes (tidymodels), ie. allows reproduce preprocessing different dataset later - useful want create forecasts. Also part dataset specification history size model use make predictions size horizon (ie many time-steps ahead) want generate predictions. Consider following diagram represent time series Time series tft feeds data model slices fixed history size, call lookback fixed number timesteps ahead calling horizon. represented diagram : Slices Now lets create tft dataset specification. don’t need manually specfy unknown covariates , unmentioned variables automatically treated . print method spec shows useful information specification: see didn’t specify lookback horizon, let’s add spec. lookback usually works like hyperparameter general choose values 10 1000 depending time series period. Horizon chosen statisfy business needs, ie. want predictions 30 days ahead, choose . now execute prep prepare spec: print method now shows name variables used model role. Also shows information number slices used.","code":"spec <- tft_dataset_spec(rec, train) %>%    spec_covariate_index(date) %>%    spec_covariate_keys(system) %>%   spec_covariate_known(time_since_begining, starts_with(\"date_\")) spec #> A <tft_dataset_spec> with: #>  #> ✖ `lookback` and `horizon` are not set. Use `spec_time_splits()`  #>  #> ── Covariates:  #> ✔ `index`: date #> ✔ `keys`: <list: system> #> ! `static` is not set. Use `spec_covariate_static()` to set it. #> ✔ `known`: <list: time_since_begining, starts_with(\"date_\")> #> ! `unknown` is not set. Covariates that are not listed as other types are considered `unknown`. #>  #> ℹ Call `prep()` to prepare the specification. spec <- spec %>%    spec_time_splits(lookback = 5*12, horizon = 12) spec <- prep(spec) spec #> A <prepared_tft_dataset_spec> with: #>  #> ✔ lookback = 60 and horizon = 12. #> ✔ The number of possible slices is 6,413 #>  #> ── Covariates:  #> ✔ `index`: date #> ✔ `keys`: system #> ✔ `static`:  #> ✔ `known`: time_since_begining, date_week, date_month, and date_wday #> ✔ `unknown`: volume_variation, volume_operational, pluviometric_daily, pluviometric_month, and pluviometric_hist #> ℹ Variables that are not specified in other types are considered `unknown`. #>  #> ℹ Call `transform()` to apply this spec to a different dataset."},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting the model","title":"Getting started","text":"now fit model. first initialize model : model luz module, thus can use luz workflows train model. example, can use lr_finder function find best learning rate model.  allows us choose learning rate. start 1e-3. Let’s redefine model now fixing learning rate: can fit model using fit. Since model luz module mainly calling ?fit.luz_module_generator , arguments apply.  can evaluate model test set using luz::evaluate function: happy results model can make forecasts using forecast function. model trained can make predictions 12 weeks ahead. default forecast generates predictions period right data model trained. can pass past_data argument make predictions recent period. return value forecast tibble containing predictions time serie 12 weeks ahead. can show predictions plot:","code":"model <- temporal_fusion_transformer(   spec,    hidden_state_size = 50,   learn_rate = 1e-3,    dropout = 0.5,    num_attention_heads = 1,    num_lstm_layers = 1 ) model #> <luz_module_generator> result <- luz::lr_finder(   model,    transform(spec, train),    end_lr = 1,   dataloader_options = list(     batch_size = 64   ),   verbose = TRUE ) #> Epoch 1/999999 plot(result) + ggplot2::coord_cartesian(ylim = c(0.15, 0.5)) model <- temporal_fusion_transformer(   spec,    hidden_state_size = 50,   learn_rate = 1e-3,    dropout = 0.5,    num_attention_heads = 1,    num_lstm_layers = 1 ) fitted <- model %>%    fit(     transform(spec),     valid_data = transform(spec, new_data = valid),     epochs = 100,     callbacks = list(       luz::luz_callback_keep_best_model(monitor = \"valid_loss\"),       luz::luz_callback_early_stopping(         monitor = \"valid_loss\",          patience = 5,          min_delta = 0.001       )     ),     verbose = FALSE,     dataloader_options = list(batch_size = 64, num_workers = 4)   ) plot(fitted) fitted %>%    luz::evaluate(     transform(spec, new_data = test, past_data = bind_rows(train, valid))   ) #> A `luz_module_evaluation` #> ── Results ───────────────────────────────────────────────────────────────────── #> loss: 0.1433 #> q10: 0.0747 #> q50: 0.2282 #> q90: 0.1269 forecasts <- generics::forecast(fitted, past_data = reservoirs) glimpse(forecasts) #> Rows: 84 #> Columns: 5 #> $ date        <date> 2022-05-29, 2022-06-05, 2022-06-12, 2022-06-19, 2022-06-2… #> $ system      <chr> \"Alto Tietê\", \"Alto Tietê\", \"Alto Tietê\", \"Alto Tietê\", \"A… #> $ .pred_lower <dbl> 55.06366, 54.53058, 54.86599, 52.85326, 52.19434, 50.61832… #> $ .pred       <dbl> 59.26833, 58.52310, 57.72558, 57.14611, 57.28476, 55.95859… #> $ .pred_upper <dbl> 63.95515, 64.07766, 63.59456, 64.05590, 63.60314, 63.37445… reservoirs %>%    filter(date > lubridate::ymd(\"2019-01-01\")) %>%    full_join(forecasts) %>%    ggplot(aes(x = date, y = volume_percentage)) +   geom_line() +   geom_line(aes(y = .pred), color = \"blue\") +   geom_ribbon(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = 0.3) +   facet_wrap(~system)"},{"path":"https://mlverse.github.io/tft/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Falbel. Author, maintainer. RStudio. Copyright holder. Christophe Regouby. Author.","code":""},{"path":"https://mlverse.github.io/tft/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Falbel D, Regouby C (2022). tft: Implementation Temporal Fusion Transformer. R package version 0.0.0.9000, https://mlverse.github.io/tft/.","code":"@Manual{,   title = {tft: Implementation of Temporal Fusion Transformer},   author = {Daniel Falbel and Christophe Regouby},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://mlverse.github.io/tft/}, }"},{"path":"https://mlverse.github.io/tft/index.html","id":"tft","dir":"","previous_headings":"","what":"Implementation of Temporal Fusion Transformer","title":"Implementation of Temporal Fusion Transformer","text":"R implementation : tft: Temporal Fusion Transformer. code repository R port akeskiner/Temporal_Fusion_Transform PyTorch’s implementation using torch package.","code":""},{"path":"https://mlverse.github.io/tft/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Implementation of Temporal Fusion Transformer","text":"can install development version {tft} GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"mlverse/tft\")"},{"path":"https://mlverse.github.io/tft/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Implementation of Temporal Fusion Transformer","text":"","code":"library(tft) library(rsample) suppressMessages(library(recipes)) suppressMessages(library(yardstick)) suppressMessages(library(tsibble)) set.seed(1)  data(\"vic_elec\", package = \"tsibbledata\") vic_elec <- vic_elec %>%    mutate(Location = as.factor(\"Victoria\"))  str(vic_elec) #> tbl_ts [52,608 × 6] (S3: tbl_ts/tbl_df/tbl/data.frame) #>  $ Time       : POSIXct[1:52608], format: \"2012-01-01 00:00:00\" \"2012-01-01 00:30:00\" ... #>  $ Demand     : num [1:52608] 4383 4263 4049 3878 4036 ... #>  $ Temperature: num [1:52608] 21.4 21.1 20.7 20.6 20.4 ... #>  $ Date       : Date[1:52608], format: \"2012-01-01\" \"2012-01-01\" ... #>  $ Holiday    : logi [1:52608] TRUE TRUE TRUE TRUE TRUE TRUE ... #>  $ Location   : Factor w/ 1 level \"Victoria\": 1 1 1 1 1 1 1 1 1 1 ... #>  - attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame) #>   ..$ .rows: list<int> [1:1]  #>   .. ..$ : int [1:52608] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..@ ptype: int(0)  #>  - attr(*, \"index\")= chr \"Time\" #>   ..- attr(*, \"ordered\")= logi TRUE #>  - attr(*, \"index2\")= chr \"Time\" #>  - attr(*, \"interval\")= interval [1:1] 30m #>   ..@ .regular: logi TRUE vic_elec_split <- initial_time_split(vic_elec, prop=3/4, lag=96)    vic_elec_train <- training(vic_elec_split) vic_elec_test <- testing(vic_elec_split)  rec <- recipe(Demand ~ ., data = vic_elec_train) %>%   update_role(Date, new_role=\"id\") %>%   update_role(Time, new_role=\"time\") %>%   update_role(Temperature, new_role=\"observed_input\") %>%   update_role(Holiday, new_role=\"known_input\") %>%   update_role(Location, new_role=\"static_input\") %>%   step_normalize(all_numeric(), -all_outcomes())   fit <- tft_fit(rec, vic_elec_train, epochs = 100, batch_size=100, total_time_steps=12, num_encoder_steps=10, verbose=TRUE)  yhat <- predict(fit, rec, vic_elec_test)"},{"path":"https://mlverse.github.io/tft/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a model\nSee generics::fit() for more information. — fit","title":"Fit a model\nSee generics::fit() for more information. — fit","text":"Fit model See generics::fit() information.","code":""},{"path":"https://mlverse.github.io/tft/reference/fit.tft_module.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit the Temporal Fusion Transformer module — fit.tft_module","title":"Fit the Temporal Fusion Transformer module — fit.tft_module","text":"Fit Temporal Fusion Transformer module","code":""},{"path":"https://mlverse.github.io/tft/reference/fit.tft_module.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit the Temporal Fusion Transformer module — fit.tft_module","text":"","code":"# S3 method for tft_module fit(object, ...)"},{"path":"https://mlverse.github.io/tft/reference/fit.tft_module.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit the Temporal Fusion Transformer module — fit.tft_module","text":"object TFT module created temporal_fusion_transformer(). ... Arguments passed luz::fit.luz_module_generator().","code":""},{"path":"https://mlverse.github.io/tft/reference/forecast.tft_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate forecasts for TFT models — forecast.tft_result","title":"Generate forecasts for TFT models — forecast.tft_result","text":"forecast can used model object include known predictors must exist data. fine recipe passed tft_dataset_spec() computes known predictors though.","code":""},{"path":"https://mlverse.github.io/tft/reference/forecast.tft_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate forecasts for TFT models — forecast.tft_result","text":"","code":"# S3 method for tft_result forecast(object, horizon = NULL, past_data = NULL)"},{"path":"https://mlverse.github.io/tft/reference/forecast.tft_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate forecasts for TFT models — forecast.tft_result","text":"object tft_result object used create predictions. horizon Number time steps ahead generate predictions. past_data NULL data model trained used. Predictions made period right past_data.","code":""},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mlverse.github.io/tft/reference/predict.tft_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict for TFT — predict.tft_result","title":"Predict for TFT — predict.tft_result","text":"Predict TFT","code":""},{"path":"https://mlverse.github.io/tft/reference/predict.tft_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict for TFT — predict.tft_result","text":"","code":"# S3 method for tft_result predict(object, new_data = NULL, ..., past_data = NULL)"},{"path":"https://mlverse.github.io/tft/reference/predict.tft_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict for TFT — predict.tft_result","text":"object model object prediction desired. new_data data.frame() containing dataset generate predictions . general used pass static known information generate forecasts. ... arguments passed predict.luz_module_fitted(). past_data data.frame() past information creating predictions. include least lookback values - can . concatenated new_data passing forward. NULL, data used train model used.","code":""},{"path":"https://mlverse.github.io/tft/reference/prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a specification\nSee recipes::prep() for more information. — prep","title":"Prepare a specification\nSee recipes::prep() for more information. — prep","text":"Prepare specification See recipes::prep() information.","code":""},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Defines rolling slices — rolling_predict","title":"Defines rolling slices — rolling_predict","text":"Sometimes validation testing data values horizon model still want create predictions time step . rolling_slice generates slices can useful debuging purposes.","code":""},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Defines rolling slices — rolling_predict","text":"","code":"rolling_predict(object, past_data, new_data, step = NULL)  rolling_slice(object, past_data, new_data, step = NULL)"},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Defines rolling slices — rolling_predict","text":"object model object prediction desired. past_data data.frame() past information creating predictions. include least lookback values - can . concatenated new_data passing forward. NULL, data used train model used. new_data data.frame() containing dataset generate predictions . general used pass static known information generate forecasts. step Default step horizon o model, way one prediction per slice.","code":""},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Defines rolling slices — rolling_predict","text":"function combine past_data (can also include training data) create slices create predictions value new_data.","code":""},{"path":"https://mlverse.github.io/tft/reference/rolling_predict.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Defines rolling slices — rolling_predict","text":"rolling_slice: Generate slices predictions without adding predictions.","code":""},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Group normalization — step_group_normalize","title":"Group normalization — step_group_normalize","text":"recipes::recipe() step normalizing data per group. times want normalize time series independently might different scales.","code":""},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group normalization — step_group_normalize","text":"","code":"step_group_normalize(   recipe,   ...,   groups,   stats = NULL,   role = NA,   trained = FALSE,   skip = FALSE,   id = recipes::rand_id(\"group_normalize\") )"},{"path":"https://mlverse.github.io/tft/reference/step_group_normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group normalization — step_group_normalize","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables step. See selections() details. groups <tidy-select> Columns group computing normalization statistics. stats modified prep. data frame containing one row per distinct group, containing normalization statistics. role used step since new variables created. trained logical indicate quantities preprocessing estimated. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion transformer — temporal_fusion_transformer","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"Temporal Fusion transformer Configuration tft model","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"","code":"temporal_fusion_transformer(spec, ...)  tft_config(   hidden_state_size = 16,   num_attention_heads = 4,   num_lstm_layers = 2,   dropout = 0.1,   optimizer = \"adam\",   learn_rate = 0.01,   quantiles = c(0.1, 0.5, 0.9) )"},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"spec spec created tft_dataset_spec(). required model depends information created/defined dataset. ... Additional parameters passed tft_config(). hidden_state_size Hidden size network main hyperparameter can range 8 512. also known d_model across paper. num_attention_heads Number attention heads Multi-head attention layer. paper refer m_H. 4 good default. num_lstm_layers Number LSTM layers used Locality Enhancement Layer. Usually 2 good enough. dropout Dropout rate used many places architecture. optimizer Optimizer used training. Can string 'adam', 'sgd', 'adagrad'. Can also torch::optimizer(). learn_rate Leaning rate used optimizer. quantiles numeric vector 3 quantiles quantile loss. first treated lower bound interval, second point prediction thir upper bound.","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"luz_module setup ready fitted.","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Temporal Fusion transformer — temporal_fusion_transformer","text":"temporal_fusion_transformer: Create tft module tft_config: Configuration Temporal Fusion Transformer","code":""},{"path":[]},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"Temporal Fusion Transformer Module","code":""},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"","code":"temporal_fusion_transformer_model(   num_features,   feature_sizes,   hidden_state_size = 100,   dropout = 0.1,   num_heads = 4,   num_lstm_layers = 2,   num_quantiles = 3 )"},{"path":"https://mlverse.github.io/tft/reference/temporal_fusion_transformer_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion Transformer Module — temporal_fusion_transformer_model","text":"num_features list containing shapes necessary information define size layers, including: - $encoder$past$(num|cat): shape past features - $encoder$static$(num|cat): shape static features - $decoder$target: shape target variable exclude batch dimension. feature_sizes number unique elements categorical variable dataset. hidden_state_size size model shared accross multiple parts architecture. dropout Dropout rate used many different places network num_heads Number heads attention layer. num_lstm_layers Number LSTM layers used Locality Enhancement Layer. Usually 2 good enough. num_quantiles number quantiles predicting .","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a TFT data specification — tft_dataset_spec","title":"Creates a TFT data specification — tft_dataset_spec","text":"used create torch::dataset()s training model, take care target normalization allow initializing temporal_fusion_transformer() model, requires specification passed first argument.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a TFT data specification — tft_dataset_spec","text":"","code":"tft_dataset_spec(x, ...)  spec_time_splits(spec, lookback, horizon, step = 1L)  spec_covariate_index(spec, index)  spec_covariate_keys(spec, ...)  spec_covariate_known(spec, ...)  spec_covariate_unknown(spec, ...)  spec_covariate_static(spec, ...)"},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a TFT data specification — tft_dataset_spec","text":"x recipe data.frame used obtain statiscs preparing recipe preparing dataset. ... Column names, selected using tidyselect. See <tidy-select> information. spec spec created tft_dataset_spec(). lookback Number timesteps used historic data prediction. horizon Number timesteps ahead predicted model. step Number steps slices. index column name indexes data. Usually date column.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a TFT data specification — tft_dataset_spec","text":"tft_dataset_spec can add spec_ functions using |> (pipe) prep() done transform() obtain torch::dataset()s.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Creates a TFT data specification — tft_dataset_spec","text":"spec_time_splits: Sets lookback horizon parameters. spec_covariate_index: Sets index column. spec_covariate_keys: Sets keys - variables define time series spec_covariate_known: Sets known time varying covariates. spec_covariate_unknown: Sets unknown time varying covariates. spec_covariate_static: Sets static covariates.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_dataset_spec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a TFT data specification — tft_dataset_spec","text":"","code":"if (torch::torch_is_installed()) { sales <- walmartdata::walmart_sales %>%   dplyr::filter(Store == 1, Dept %in% c(1,2))  rec <- recipes::recipe(Weekly_Sales ~ ., sales)  spec <- tft_dataset_spec(rec, sales) %>%   spec_time_splits(lookback = 52, horizon = 4) %>%   spec_covariate_index(Date) %>%   spec_covariate_keys(Store, Dept) %>%   spec_covariate_static(Type, Size) %>%   spec_covariate_known(starts_with(\"MarkDown\"))  print(spec)  spec <- prep(spec) dataset <- transform(spec) # this is a torch dataset. str(dataset[1]) } #> A <tft_dataset_spec> with: #>  #> ✔ lookback = 52 and horizon = 4. #>  #> ── Covariates:  #> ✔ `index`: Date #> ✔ `keys`: <list: Store, Dept> #> ✔ `static`: <list: Type, Size> #> ✔ `known`: <list: starts_with(\"MarkDown\")> #> ! `unknown` is not set. Covariates that are not listed as other types are considered `unknown`. #>  #> ℹ Call `prep()` to prepare the specification. #> List of 2 #>  $ :List of 2 #>   ..$ encoder:List of 2 #>   .. ..$ past  :List of 2 #>   .. .. ..$ num:Float [1:52, 1:11] #>   .. .. ..$ cat:Float [1:0, 1:0] #>   .. ..$ static:List of 2 #>   .. .. ..$ num:Float [1:3] #>   .. .. ..$ cat:Long [1:1] #>   ..$ decoder:List of 2 #>   .. ..$ known :List of 2 #>   .. .. ..$ num:Float [1:4, 1:5] #>   .. .. ..$ cat:Float [1:0, 1:0] #>   .. ..$ target:List of 2 #>   .. .. ..$ num:Float [1:4, 1:1] #>   .. .. ..$ cat:Float [1:0, 1:0] #>  $ :Float [1:4, 1:1]"},{"path":"https://mlverse.github.io/tft/news/index.html","id":"tft-0009000","dir":"Changelog","previous_headings":"","what":"tft 0.0.0.9000","title":"tft 0.0.0.9000","text":"remove constraint development versions torch:: recipe:: Added NEWS.md file track changes package.","code":""}]
