[{"path":"https://mlverse.github.io/tft/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 tft authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"preparing-the-data","dir":"Articles","previous_headings":"","what":"Preparing the data","title":"Getting started","text":"tft uses tsibble specify time time columns keys - want create forecasts multiple timeseries single model. let’s first, transform data.frame tbl_ts. weekly observations Store Department, since Type Size informations don’t vary time also added ‘keys’ tsibble. specify index column Date column. tsibble correctly identifies weekly period ([7D]) shows us 3331 different time series want create predictions . tft also uses recipes ppackage specify response variables, predictors types. can also use recipes specify transformations data used model. default keys tsibble considered ‘static’ predictors, ie, don’t vary time time series. can remove role ‘predictor’ don’t want used predictor. can also ‘known’ predictors: vary time regular way thus can compute time step, even future ones - like ‘IsHoliday’ information like day week similar. expect able specify every time point using forecast function. index variable used model, unless transformed. predictors considered ‘observed’ predictors thus ‘past’ values used model. Past values response variable also used ‘observed’ values model. ’s recommended include features represent seasonality known predictors TFT model, like mon, day week etc. ’s also recommended normalize predictors treat missing values model don’t treat implicitly. can bake prep juice recipe see transformations working:","code":"sales <- tsibble::tsibble(   walmart_sales, key = c(Store, Dept, Type, Size),    index = Date ) sales #> # A tsibble: 421,570 x 16 [7D] #> # Key:       Store, Dept, Type, Size [3,331] #>    Store  Dept Date       Weekly_Sales Type    Size Temperature Fuel_Price #>    <dbl> <dbl> <date>            <dbl> <chr>  <dbl>       <dbl>      <dbl> #>  1     1     1 2010-02-05       24924. A     151315        42.3       2.57 #>  2     1     1 2010-02-12       46039. A     151315        38.5       2.55 #>  3     1     1 2010-02-19       41596. A     151315        39.9       2.51 #>  4     1     1 2010-02-26       19404. A     151315        46.6       2.56 #>  5     1     1 2010-03-05       21828. A     151315        46.5       2.62 #>  6     1     1 2010-03-12       21043. A     151315        57.8       2.67 #>  7     1     1 2010-03-19       22137. A     151315        54.6       2.72 #>  8     1     1 2010-03-26       26229. A     151315        51.4       2.73 #>  9     1     1 2010-04-02       57258. A     151315        62.3       2.72 #> 10     1     1 2010-04-09       42961. A     151315        65.9       2.77 #> # … with 421,560 more rows, and 8 more variables: MarkDown1 <dbl>, #> #   MarkDown2 <dbl>, MarkDown3 <dbl>, MarkDown4 <dbl>, MarkDown5 <dbl>, #> #   CPI <dbl>, Unemployment <dbl>, IsHoliday <lgl> rec <- recipe(Weekly_Sales ~ ., data = sales) %>%    add_role(IsHoliday, new_role = \"known\") %>%    step_date(Date, role = \"known\", features = c(\"year\", \"month\", \"doy\")) %>%    step_normalize(all_numeric_predictors()) %>%    step_indicate_na(starts_with(\"MarkDown\")) %>%    step_impute_mean(starts_with(\"Markdown\")) rec %>% prep() %>% juice() %>% glimpse() #> Rows: 421,570 #> Columns: 24 #> $ Store            <dbl> -1.658197, -1.658197, -1.658197, -1.658197, -1.658197… #> $ Dept             <dbl> -1.418741, -1.418741, -1.418741, -1.418741, -1.418741… #> $ Date             <date> 2010-02-05, 2010-02-12, 2010-02-19, 2010-02-26, 2010… #> $ Type             <fct> A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A,… #> $ Size             <dbl> 0.2392087, 0.2392087, 0.2392087, 0.2392087, 0.2392087… #> $ Temperature      <dbl> -0.9637969, -1.1697821, -1.0928087, -0.7296243, -0.73… #> $ Fuel_Price       <dbl> -1.720832, -1.773175, -1.847328, -1.744823, -1.605241… #> $ MarkDown1        <dbl> 1.401583e-17, 1.401583e-17, 1.401583e-17, 1.401583e-1… #> $ MarkDown2        <dbl> -1.457308e-17, -1.457308e-17, -1.457308e-17, -1.45730… #> $ MarkDown3        <dbl> 9.280565e-19, 9.280565e-19, 9.280565e-19, 9.280565e-1… #> $ MarkDown4        <dbl> 7.901976e-18, 7.901976e-18, 7.901976e-18, 7.901976e-1… #> $ MarkDown5        <dbl> 6.785472e-17, 6.785472e-17, 6.785472e-17, 6.785472e-1… #> $ CPI              <dbl> 1.0187730, 1.0224965, 1.0236961, 1.0244749, 1.0252538… #> $ Unemployment     <dbl> 0.07820083, 0.07820083, 0.07820083, 0.07820083, 0.078… #> $ IsHoliday        <lgl> FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE… #> $ Weekly_Sales     <dbl> 24924.50, 46039.49, 41595.55, 19403.54, 21827.90, 210… #> $ Date_year        <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010,… #> $ Date_month       <fct> Feb, Feb, Feb, Feb, Mar, Mar, Mar, Mar, Apr, Apr, Apr… #> $ Date_doy         <dbl> 36, 43, 50, 57, 64, 71, 78, 85, 92, 99, 106, 113, 120… #> $ na_ind_MarkDown1 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown2 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown3 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown4 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ na_ind_MarkDown5 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…"},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"metrics-and-validation","dir":"Articles","previous_headings":"","what":"Metrics and validation","title":"Getting started","text":"Now think size horizon want create forecasts . single week ahead ten, influence split data training, validation testing. really data analysis decision business decision, ie: many weeks ahead want know can plan demand etc. Let’s say want 4 weeks ahead, ie ~1 month. rsample package provides sliding_* functions useful task creating time splits. Now can separate splits , training testing, ie: used cross-validation choosing hyperparamerters, others used testing model. going use last 4 splits testing first 5 cross validate. Note: selected 4 weeks horizon predictions. need use value specifying horizon tft model.","code":"resamples <- sliding_period(   arrange(sales, Date),   index = Date,   period = \"week\",   lookback = Inf,   assess_stop = 4,   step = 4,   skip = 104 ) train_splits <- resamples %>% slice(1:5) test_splits <- resamples %>% slice(-c(1:5))"},{"path":"https://mlverse.github.io/tft/articles/Getting-started.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting the model","title":"Getting started","text":"can now tune tft model compute metrics using: happy tuning can finalize workflow obtain metrics test splits. obtain predictions future observations, first need load data.frame includes known predictors like IsHoliday variable time steps future data frame. can call forecast predict obtain predictions future data. Note forecast predict currently can predict horizon time steps ahead. don’t provide away rolling forecasts.","code":"model <- workflow() %>%    add_recipe(rec) %>%    add_model(tft(horizon = 4))  grid <- grid_regular(model, levels = 5)  results <- tune_grid(   model,   resamples,   grid )  collect_metrics(results) #> # A tibble: 5 × 4 #>   epochs hidden_layer_size training_tau   rmse #>    <dbl>             <dbl>        <dbl>  <dbl> #> 1      1               160        0.3   0.295  #> 2      5               500        0.003 0.0218 #> 3      7               300        0.1   0.545  #> 4      1               160        0.5   0.465  #> 5      5               500        0.003 0.954 final_params <- select_best(results, metric = \"rmse\") workflow <- finalize_workflow(model, final_params) results <- fit_resamples(model, test_splits) collect_metrics(results) #> # A tibble: 1 × 2 #>   metric value #>   <chr>  <dbl> #> 1 rmse   0.001 final_model <- fit(model, sales) final_predictions <- forecast(model, new_data = newdata) final_predictions #> # A tsibble: 13,324 x 6 [7D] #> # Key:       Store, Dept, Type, Size [3,331] #>    Store  Dept Date       Type    Size  .pred #>    <dbl> <dbl> <date>     <chr>  <dbl>  <dbl> #>  1     1     1 2012-11-02 A     151315   311. #>  2     1     1 2012-11-09 A     151315  4421. #>  3     1     1 2012-11-16 A     151315 11085. #>  4     1     1 2012-11-23 A     151315  7216. #>  5     1     2 2012-11-02 A     151315  1474. #>  6     1     2 2012-11-09 A     151315 33240. #>  7     1     2 2012-11-16 A     151315  2639. #>  8     1     2 2012-11-23 A     151315  1472. #>  9     1     3 2012-11-02 A     151315  4877. #> 10     1     3 2012-11-09 A     151315 27584. #> # … with 13,314 more rows"},{"path":"https://mlverse.github.io/tft/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Falbel. Author, maintainer. RStudio. Copyright holder. Christophe Regouby. Author.","code":""},{"path":"https://mlverse.github.io/tft/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Falbel D, Regouby C (2022). tft: Implementation Temporal Fusion Transformer. R package version 0.0.0.9000, https://mlverse.github.io/tft/.","code":"@Manual{,   title = {tft: Implementation of Temporal Fusion Transformer},   author = {Daniel Falbel and Christophe Regouby},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://mlverse.github.io/tft/}, }"},{"path":"https://mlverse.github.io/tft/index.html","id":"tft","dir":"","previous_headings":"","what":"Implementation of Temporal Fusion Transformer","title":"Implementation of Temporal Fusion Transformer","text":"R implementation : tft: Temporal Fusion Transformer. code repository R port akeskiner/Temporal_Fusion_Transform PyTorch’s implementation using torch package.","code":""},{"path":"https://mlverse.github.io/tft/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Implementation of Temporal Fusion Transformer","text":"can install development version {tft} GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"mlverse/tft\")"},{"path":"https://mlverse.github.io/tft/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Implementation of Temporal Fusion Transformer","text":"","code":"library(tft) library(rsample) suppressMessages(library(recipes)) suppressMessages(library(yardstick)) suppressMessages(library(tsibble)) set.seed(1)  data(\"vic_elec\", package = \"tsibbledata\") vic_elec <- vic_elec %>%    mutate(Location = as.factor(\"Victoria\"))  str(vic_elec) #> tbl_ts [52,608 × 6] (S3: tbl_ts/tbl_df/tbl/data.frame) #>  $ Time       : POSIXct[1:52608], format: \"2012-01-01 00:00:00\" \"2012-01-01 00:30:00\" ... #>  $ Demand     : num [1:52608] 4383 4263 4049 3878 4036 ... #>  $ Temperature: num [1:52608] 21.4 21.1 20.7 20.6 20.4 ... #>  $ Date       : Date[1:52608], format: \"2012-01-01\" \"2012-01-01\" ... #>  $ Holiday    : logi [1:52608] TRUE TRUE TRUE TRUE TRUE TRUE ... #>  $ Location   : Factor w/ 1 level \"Victoria\": 1 1 1 1 1 1 1 1 1 1 ... #>  - attr(*, \"key\")= tibble [1 × 1] (S3: tbl_df/tbl/data.frame) #>   ..$ .rows: list<int> [1:1]  #>   .. ..$ : int [1:52608] 1 2 3 4 5 6 7 8 9 10 ... #>   .. ..@ ptype: int(0)  #>  - attr(*, \"index\")= chr \"Time\" #>   ..- attr(*, \"ordered\")= logi TRUE #>  - attr(*, \"index2\")= chr \"Time\" #>  - attr(*, \"interval\")= interval [1:1] 30m #>   ..@ .regular: logi TRUE vic_elec_split <- initial_time_split(vic_elec, prop=3/4, lag=96)    vic_elec_train <- training(vic_elec_split) vic_elec_test <- testing(vic_elec_split)  rec <- recipe(Demand ~ ., data = vic_elec_train) %>%   update_role(Date, new_role=\"id\") %>%   update_role(Time, new_role=\"time\") %>%   update_role(Temperature, new_role=\"observed_input\") %>%   update_role(Holiday, new_role=\"known_input\") %>%   update_role(Location, new_role=\"static_input\") %>%   step_normalize(all_numeric(), -all_outcomes())   fit <- tft_fit(rec, vic_elec_train, epochs = 100, batch_size=100, total_time_steps=12, num_encoder_steps=10, verbose=TRUE)  yhat <- predict(fit, rec, vic_elec_test)"},{"path":"https://mlverse.github.io/tft/reference/batch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"conditionning input data into tensors according to tft variable roles — batch_data","title":"conditionning input data into tensors according to tft variable roles — batch_data","text":"conditionning input data tensors according tft variable roles","code":""},{"path":"https://mlverse.github.io/tft/reference/batch_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"conditionning input data into tensors according to tft variable roles — batch_data","text":"","code":"batch_data(recipe, df, total_time_steps = 12, device)"},{"path":"https://mlverse.github.io/tft/reference/batch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"conditionning input data into tensors according to tft variable roles — batch_data","text":"recipe recipe affecting tft roles df df data frame total_time_steps time_step value (default 48) device device use training. cpu cuda. default (auto) uses cuda available, otherwise uses cpu.","code":""},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://mlverse.github.io/tft/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://mlverse.github.io/tft/reference/tft_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Configuration for Tft models — tft_config","title":"Configuration for Tft models — tft_config","text":"Configuration Tft models","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Configuration for Tft models — tft_config","text":"","code":"tft_config(   batch_size = 256,   clip_value = NULL,   loss = \"quantile_loss\",   epochs = 5,   drop_last = FALSE,   total_time_steps = NULL,   num_encoder_steps = NULL,   quantiles = list(0.5),   training_tau = 0.3,   virtual_batch_size = 256,   valid_split = 0,   learn_rate = 0.02,   optimizer = \"adam\",   lr_scheduler = NULL,   lr_decay = 0.1,   step_size = 30,   checkpoint_epochs = 10,   cat_emb_dim = 1,   hidden_layer_size = 160,   dropout_rate = 0.3,   stack_size = 3,   num_heads = 1,   verbose = FALSE,   device = \"auto\" )"},{"path":"https://mlverse.github.io/tft/reference/tft_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Configuration for Tft models — tft_config","text":"batch_size (int) Number examples per batch, large batch sizes recommended. (default: 1024) clip_value float given clip gradient clip_value. Pass NULL (default) clip. loss (character function) Loss function training within \"quantile_loss\", \"pinball_loss\", \"rmsse_loss\", \"smape_loss\" (default quantile_loss) epochs (int) Number training epochs. drop_last (bool) Whether drop last batch complete training total_time_steps (int) Size look-back time window + forecast horizon steps. width Temporal fusion decoder N. num_encoder_steps (int) Size look-back time window steps. size LSTM encoder. quantiles (list) list quantiles forcasts used quantile loss. (default = list(0.5)). training_tau (float) training_tau value used pinball loss. (default = 0.3). virtual_batch_size (int) Size mini batches used Batch Normalization (default=256) valid_split (float) fraction dataset used validation. learn_rate initial learning rate optimizer. optimizer optimization method. currently 'adam' supported, can also pass torch optimizer function. lr_scheduler NULL, (default) learning rate decay used. step decays learning rate lr_decay every step_size epochs. can also torch::lr_scheduler function takes optimizer parameter. step method called per epoch. lr_decay multiplies initial learning rate lr_decay every step_size epochs. Unused lr_scheduler torch::lr_scheduler NULL. step_size number epoch modifying learning rate lr_decay. Unused lr_scheduler torch::lr_scheduler NULL. checkpoint_epochs checkpoint model weights architecture every checkpoint_epochs. (default 10). may cause large memory usage. Use 0 disable checkpoints. cat_emb_dim (int list) Embedding size categorial features, broadcasted categorical feature, per categorical feature list size categorical features  (default=1) hidden_layer_size (int)size Internal state layer (default=160). dropout_rate dropout rate applied nn block (default=0.3) stack_size (int) Number self-attention layers apply (default=3). Use 1 basic TFT. num_heads (int) number interpretable multi-attention head (default=1) verbose (bool) wether print progress loss values training. device device use training. cpu cuda. default (auto) uses cuda`` available, otherwise uses cpu`.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Configuration for Tft models — tft_config","text":"named list hyperparameters TabNet implementation.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion Transformer model — tft_fit","title":"Temporal Fusion Transformer model — tft_fit","text":"Fits Temporal Fusion Transformer Interpretable Multi-horizon Time Series Forecasting model","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion Transformer model — tft_fit","text":"","code":"tft_fit(x, ...)  # S3 method for default tft_fit(x, ...)  # S3 method for recipe tft_fit(x, df, tft_model = NULL, ..., from_epoch = NULL)"},{"path":"https://mlverse.github.io/tft/reference/tft_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion Transformer model — tft_fit","text":"x recipe specifying set preprocessing steps created recipes::recipe(). predictor data standardized (e.g. centered scaled). model treats categorical predictors internally thus, need make treatment. ... Model hyperparameters. See tft_config() list possible hyperparameters. df data frame containing predictors outcome. tft_model previously fitted TFT model object continue fitting . NULL (default) brand new model initialized. from_epoch tft_model provided, restore network weights specific epoch. Default last available checkpoint restored model, last epoch -memory model.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporal Fusion Transformer model — tft_fit","text":"TFT model object. can used serialization, predictions, fitting.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_fit.html","id":"fitting-a-pre-trained-model","dir":"Reference","previous_headings":"","what":"Fitting a pre-trained model","title":"Temporal Fusion Transformer model — tft_fit","text":"providing parent tft_model parameter, model fitting resumes model weights following epoch: last fitted epoch model already torch context Last model checkpoint epoch model loaded file epoch related checkpoint matching preceding from_epoch value provided model fitting metrics append top parent metrics returned TFT model.","code":""},{"path":"https://mlverse.github.io/tft/reference/tft_fit.html","id":"threading","dir":"Reference","previous_headings":"","what":"Threading","title":"Temporal Fusion Transformer model — tft_fit","text":"TFT uses torch backend computation torch uses available threads default. can control number threads used torch :","code":"torch::torch_set_num_threads(1) torch::torch_set_num_interop_threads(1)"},{"path":"https://mlverse.github.io/tft/reference/tft_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal Fusion Transformer model — tft_fit","text":"","code":"if (torch::torch_is_installed() && FALSE) { data(\"vic_elec\", package = \"tsibbledata\") library(recipes) rec <- recipe(Demand ~ ., data = vic_elec) %>%   update_role(Date, new_role=\"id\") %>%   update_role(Time, new_role=\"time\") %>%   update_role(Temperature, new_role=\"observed_input\") %>%   update_role(Holiday, new_role=\"known_input\") fit <- tft_fit(rec, df = vic_elec, epochs = 1, total_time_steps=10, num_encoder_steps=7) }"},{"path":"https://mlverse.github.io/tft/news/index.html","id":"tft-0009000","dir":"Changelog","previous_headings":"","what":"tft 0.0.0.9000","title":"tft 0.0.0.9000","text":"remove constraint development versions torch:: recipe:: Added NEWS.md file track changes package.","code":""}]
